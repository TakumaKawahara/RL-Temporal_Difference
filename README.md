# RL-Temporal_Difference
Udacity Deep Learning Foundation Nanodegree Program(DLND)  
  
Lesson "Temporal Difference".  
In this lesson, I learned how to implement below algorithms.  
Algorithm 1: TD Prediction: TD(0)  
Algorithm 2: TD Prediction: Action Values  
Algorithm 3: TD Control: Sarsa(0)  
Algorithm 4: TD Control: Sarsamax or Q-Learning  
Algorithm 5: TD Control: Expected Sarsa  
    
Reinforcement Learning cheatsheet  
https://github.com/udacity/rl-cheatsheet  

OpenAI Gym: CliffWalking Environment
![alt text](https://github.com/TakumaKawahara/RL-Temporal_Difference/blob/master/CliffWalkingEnv.jpg)  
  
  
Output: State-Value function
![alt text](https://github.com/TakumaKawahara/RL-Temporal_Difference/blob/master/State-value_function.png)  
  
  
Output: Average Reward  
![alt text](https://github.com/TakumaKawahara/RL-Temporal_Difference/blob/master/Reward.png)  
  

